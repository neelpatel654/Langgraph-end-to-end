{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "486305de",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "gemini_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
        "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0b717a68",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "771b0bab",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",api_key=gemini_api_key)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=gemini_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62236ae8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "urls =  [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap=50)\n",
        "\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "336fad4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retrieve_blog_posts\",\n",
        "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
        ")\n",
        "\n",
        "tools = [retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93486ad5",
      "metadata": {},
      "source": [
        "Let's look into the retriever grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "288e7bc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3667: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts  import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary Score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0a4fe2ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f38637c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "system = \"\"\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \n",
        "If the document has words or meanings related to the question, mark it as relevant.  \n",
        "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
        "    \n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ebeffff2",
      "metadata": {},
      "outputs": [],
      "source": [
        "my_retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = \"what is ai agent?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b7bb073a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Parth\\AppData\\Local\\Temp\\ipykernel_21236\\4110481353.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "docs = retriever.get_relevant_documents(question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "92b08cb5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_txt = docs[2].page_content\n",
        "doc_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "874b097b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\":question}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e8748e78",
      "metadata": {},
      "outputs": [],
      "source": [
        "question=\"who is neel patel?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "975b67fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binary_score='no'\n"
          ]
        }
      ],
      "source": [
        "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "353a6e22",
      "metadata": {},
      "source": [
        "let's look into the data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "48f81e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8703085b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
            "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ee23d060",
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "368dc866",
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"what is a AI agent?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "13a0c184",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'An AI agent is a system using a large language model (LLM) as its core, complemented by planning, memory (short-term and long-term), and tool use capabilities.  It breaks down complex tasks into smaller subgoals, learns from its actions, and utilizes external APIs for additional information.  Examples include AutoGPT, GPT-Engineer, and BabyAGI.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generation = rag_chain.invoke({\"context\": docs,\"question\":question})\n",
        "generation.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6146c1a8",
      "metadata": {},
      "source": [
        "Hallucination Grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "04160261",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no' \"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5ab45042",
      "metadata": {},
      "outputs": [],
      "source": [
        "structured_llm_grader = llm.with_structured_output(GradeHallucinations) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9c6bbde4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt\n",
        "system = \"\"\"You are a grader checking if an LLM generation is grounded in or supported by a set of retrieved facts.  \n",
        "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts and 'no'  means the generation is not grounded in or not supported by a set of retrieved the facts \"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e2fa7da8",
      "metadata": {},
      "outputs": [],
      "source": [
        "hallucination_grader = hallucination_prompt | structured_llm_grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "eb499595",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "print(hallucination_grader.invoke({\"documents\":docs,\"generation\":generation}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23fdb941",
      "metadata": {},
      "source": [
        "Answer Grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "80875654",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
        "\n",
        "    binary_score:str = Field(\n",
        "        description = \"Answer addresses the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
        "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
        "answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "answer_grader = answer_prompt | structured_llm_grader\n",
        "print(answer_grader.invoke({\"question\":question,\"generation\":generation}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ade0d4",
      "metadata": {},
      "source": [
        "Question Re-writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6d81077c",
      "metadata": {},
      "outputs": [],
      "source": [
        "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.  \n",
        "You are given both a question and a document.  \n",
        "- First, check if the question is relevant to the document by identifying a connection or relevance between them.  \n",
        "- If there is a little relevancy, rewrite the question based on the semantic intent of the question and the context of the document.  \n",
        "- If no relevance is found, simply return this single word \"question not relevant.\" dont return the entire phrase \n",
        "Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\"\n",
        "     \n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\"\"\"Here is the initial question: \\n\\n {question} \\n,\n",
        "             Here is the document: \\n\\n {documents} \\n ,\n",
        "             Formulate an improved question. if possible other return 'question not relevant'.\"\"\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0ccd2833",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'question not relevant'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question=\"who is a current indian prime minister?\"\n",
        "\n",
        "question_rewriter.invoke({\"question\":question,\"documents\":docs})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d3c2f8b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "class AgentState(TypedDict):\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[str]\n",
        "    filter_documents: List[str]\n",
        "    unfilter_documents: List[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "38b717e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve(state:AgentState):\n",
        "    print(\"----RETRIEVE----\")\n",
        "    question = state[\"question\"]\n",
        "    documents = retriever.get_relevant_documents(question)\n",
        "    return {\"documents\":documents,\"question\":question}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "70d51507",
      "metadata": {},
      "outputs": [],
      "source": [
        "def grade_documents(state:AgentState):\n",
        "    print(\"----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\")\n",
        "    question = state['question']\n",
        "    documents = state['documents']\n",
        "    \n",
        "    filtered_docs = []\n",
        "    unfiltered_docs = []\n",
        "    for doc in documents:\n",
        "        score=my_retrieval_grader.invoke({\"question\":question, \"document\":doc})\n",
        "        grade=score.binary_score\n",
        "        \n",
        "        if grade=='yes':\n",
        "            print(\"----GRADE: DOCUMENT RELEVANT----\")\n",
        "            filtered_docs.append(doc)\n",
        "        else:\n",
        "            print(\"----GRADE: DOCUMENT NOT RELEVANT----\")\n",
        "            unfiltered_docs.append(doc)\n",
        "    if len(unfiltered_docs)>1:\n",
        "        return {\"unfilter_documents\": unfiltered_docs,\"filter_documents\":[], \"question\": question}\n",
        "    else:\n",
        "        return {\"filter_documents\": filtered_docs,\"unfilter_documents\":[],\"question\": question}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4ad73d29",
      "metadata": {},
      "outputs": [],
      "source": [
        "def decide_to_generate(state:AgentState):\n",
        "    print(\"----ACCESS GRADED DOCUMENTS----\")\n",
        "    state[\"question\"]\n",
        "    unfiltered_documents = state[\"unfilter_documents\"]\n",
        "    filtered_documents = state[\"filter_documents\"]\n",
        "    print(\"Available keys in state:\", state.keys())\n",
        "    if unfiltered_documents:\n",
        "        print(\"----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\")\n",
        "        return \"transform_query\"\n",
        "    if filtered_documents:\n",
        "        print(\"----DECISION: GENERATE----\")\n",
        "        return \"generate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e67a17ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(state:AgentState):\n",
        "    print(\"----GENERATE----\")\n",
        "    question=state[\"question\"]\n",
        "    documents=state[\"documents\"]\n",
        "    \n",
        "    generation = rag_chain.invoke({\"context\": documents,\"question\":question})\n",
        "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b001dd92",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "def transform_query(state:AgentState):\n",
        "    question=state[\"question\"]\n",
        "    documents=state[\"documents\"]\n",
        "    \n",
        "    print(f\"this is my document{documents}\")\n",
        "    response = question_rewriter.invoke({\"question\":question,\"documents\":documents})\n",
        "    print(f\"----RESPONSE---- {response}\")\n",
        "    if response == 'question not relevant':\n",
        "        print(\"----QUESTION IS NOT AT ALL RELEVANT----\")\n",
        "        return {\"documents\":documents,\"question\":question,\"generation\":\"question was not at all relevant\"}\n",
        "    else:   \n",
        "        return {\"documents\":documents,\"question\":response}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f2f487b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def decide_to_generate_after_transformation(state:AgentState):\n",
        "    question=state[\"question\"]\n",
        "    \n",
        "    if question==\"question not relevant\":\n",
        "        return \"query_not_at_all_relevant\"\n",
        "    else:\n",
        "        return \"Retriever\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a492876f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pprint\n",
        "def grade_generation_vs_documents_and_question(state:AgentState):\n",
        "    print(\"---CHECK HELLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    score = hallucination_grader.invoke({\"documents\":documents,\"generation\":generation})\n",
        "    grade = score.binary_score\n",
        "    #Check hallucinations\n",
        "    if grade == 'yes':\n",
        "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "        \n",
        "        print(\"---GRADE GENERATION vs QUESTION ---\")\n",
        "\n",
        "        score = answer_grader.invoke({\"question\":question,\"generation\":generation})\n",
        "\n",
        "        grade = score.binary_score\n",
        "\n",
        "        if grade=='yes':\n",
        "            print(\"---DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
        "        \"not useful\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "55d4d2e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "12a6e2ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "def web_search(state:AgentState):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "    print(\"---WEB SEARCH---\")\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    #web search\n",
        "    docs = web_search_tool.invoke({\"query\":question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "    return {\"documents\": documents,\"question\":question}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e4683428",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(state: AgentState):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "\n",
        "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "382edd92",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28421697b00>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import START,END, StateGraph\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"Docs_Vector_Retrieve\",retrieve)\n",
        "workflow.add_node(\"Grading_Generated_Documents\",grade_documents)\n",
        "workflow.add_node(\"Content_Generator\",generate)\n",
        "workflow.add_node(\"Transform_User_Query\",transform_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3aad49c1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28421697b00>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(START,\"Docs_Vector_Retrieve\")\n",
        "workflow.add_edge(\"Docs_Vector_Retrieve\",\"Grading_Generated_Documents\")\n",
        "workflow.add_conditional_edges(\"Grading_Generated_Documents\",\n",
        "                            decide_to_generate,\n",
        "                            {\n",
        "                            \"generate\": \"Content_Generator\",\n",
        "                            \"transform_query\": \"Transform_User_Query\"\n",
        "                            }\n",
        "                            )\n",
        "workflow.add_conditional_edges(\"Content_Generator\",\n",
        "                            grade_generation_vs_documents_and_question,\n",
        "                            {\n",
        "                            \"useful\": END,\n",
        "                            \"not useful\": \"Transform_User_Query\",\n",
        "                            }\n",
        "                            )\n",
        "workflow.add_conditional_edges(\"Transform_User_Query\",\n",
        "                decide_to_generate_after_transformation,\n",
        "                {\n",
        "                \"Retriever\":\"Docs_Vector_Retrieve\",\n",
        "                \"query_not_at_all_relevant\":END\n",
        "                }\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e6b11040",
      "metadata": {},
      "outputs": [],
      "source": [
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0e099bf7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display # type: ignore\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "587b23c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# inputs = {\"question\": \"Explain how the different types of agent memory work?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "30cb7f19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# app.invoke(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9808ba57",
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = {\"question\": \"who is a first president of USA?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "f25dd65b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "Available keys in state: dict_keys(['question', 'documents', 'filter_documents', 'unfilter_documents'])\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'title': \"Prompt Engineering | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'title': \"Prompt Engineering | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='Because these documents are long, each document is split into paragraphs of 6 sentences, $\\\\{p\\\\}$. Paragraphs are ranked by TF-IDF based cosine similarity between evidence paragraphs and the query. Only the most relevant paragraph is used in the prompt to produce an answer $a$.')]\n",
            "----RESPONSE---- question not relevant\n",
            "----QUESTION IS NOT AT ALL RELEVANT----\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "Available keys in state: dict_keys(['question', 'generation', 'documents', 'filter_documents', 'unfilter_documents'])\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'language': 'en', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'title': \"Prompt Engineering | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...'), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'language': 'en', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Because these documents are long, each document is split into paragraphs of 6 sentences, $\\\\{p\\\\}$. Paragraphs are ranked by TF-IDF based cosine similarity between evidence paragraphs and the query. Only the most relevant paragraph is used in the prompt to produce an answer $a$.')]\n",
            "----RESPONSE---- question not relevant\n",
            "----QUESTION IS NOT AT ALL RELEVANT----\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 57\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 55\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2714\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2712\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2713\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2714\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2715\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2718\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2719\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2353\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2347\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2348\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2349\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2350\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2351\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2352\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2353\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2357\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2359\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2360\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2361\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:158\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    156\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:610\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m config = patch_config(\n\u001b[32m    607\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    608\u001b[39m )\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    612\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:375\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mgrade_documents\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      7\u001b[39m unfiltered_docs = []\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     score=\u001b[43mmy_retrieval_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocument\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     grade=score.binary_score\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grade==\u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5440\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5435\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5438\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5439\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5441\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5442\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:331\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     **kwargs: Any,\n\u001b[32m    327\u001b[39m ) -> BaseMessage:\n\u001b[32m    328\u001b[39m     config = ensure_config(config)\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    330\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    341\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:894\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    887\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m     **kwargs: Any,\n\u001b[32m    892\u001b[39m ) -> LLMResult:\n\u001b[32m    893\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:719\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m         )\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    727\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:960\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    964\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:961\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    936\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    937\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    948\u001b[39m     **kwargs: Any,\n\u001b[32m    949\u001b[39m ) -> ChatResult:\n\u001b[32m    950\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m    951\u001b[39m         messages,\n\u001b[32m    952\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m    959\u001b[39m         tool_choice=tool_choice,\n\u001b[32m    960\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:196\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    194\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:194\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    191\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    192\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:178\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\AI\\langgraph-end-to-end\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 55\n}\n]",
            "During task with name 'Grading_Generated_Documents' and id '2180d562-3a91-b176-c785-b6adb91e611c'"
          ]
        }
      ],
      "source": [
        "app.invoke(inputs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
